{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54ebd83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCreated: September 18, 2025\\nLast Modified: November 6, 2025\\nAuthor: Pranaydeep Singh\\nDescription: Script for fine-tuning a fine-tuned BERT model for text classification with inference.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created: September 18, 2025\n",
    "Author: Pranaydeep Singh\n",
    "Last Modified: November 6, 2025\n",
    "Modified by: Pranaydeep Singh\n",
    "Description: Script for fine-tuning a fine-tuned BERT model for text classification with inference.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8b4de1",
   "metadata": {},
   "source": [
    "# Fine-tuning BERT for Text Classification\n",
    "\n",
    "This notebook walks you through **fine-tuning a pretrained BERT model** on a text classification dataset using the ðŸ¤— Hugging Face ecosystem.\n",
    "\n",
    "## What you'll learn\n",
    "- What *fine-tuning* is and why it's useful\n",
    "- How to load an NLP dataset with `datasets`\n",
    "- How tokenization works for BERT (input IDs + attention masks)\n",
    "- How to train and evaluate with the `Trainer` API\n",
    "- How to save a model and run inference on new texts\n",
    "\n",
    "> Tip: Please follow the instructions in the README to install the required packages before proceeding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ce1389",
   "metadata": {},
   "source": [
    "## 1) Imports + Quick environment check\n",
    "\n",
    "We use:\n",
    "- **transformers**: models, tokenizers, and the training utilities\n",
    "- **datasets**: easy access to standard NLP datasets + fast preprocessing\n",
    "- **evaluate**: standard evaluation metrics (accuracy, F1, etc.)\n",
    "\n",
    "We'll also set a random seed so results are more reproducible.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0845156f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 2.9.1+cu128\n",
      "CUDA available: True\n",
      "GPU: Tesla V100-SXM2-16GB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    set_seed,\n",
    ")\n",
    "\n",
    "print('PyTorch:', torch.__version__)\n",
    "print('CUDA available:', torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print('GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5afeaa",
   "metadata": {},
   "source": [
    "## 2) Choose a model + dataset\n",
    "\n",
    "### Model\n",
    "We'll start from a pretrained checkpoint: **`bert-base-uncased`**.\n",
    "\n",
    "- *Pretrained* means it already learned general language patterns from lots of text.\n",
    "- *Fine-tuning* means we add a small classification head and train on our labeled dataset.\n",
    "\n",
    "### Dataset\n",
    "We'll use **AG News** (`ag_news`), a classic 4-class topic classification dataset.\n",
    "\n",
    "The dataset contains:\n",
    "- `text`: the news headline + snippet\n",
    "- `label`: an integer class id\n",
    "\n",
    "We'll create a small validation split from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26058d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120000/120000 [00:00<00:00, 237351.63 examples/s]\n",
      "Generating test split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7600/7600 [00:00<00:00, 134575.84 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 120000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 7600\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAME = 'bert-base-uncased'\n",
    "DATASET_NAME = 'ag_news'\n",
    "\n",
    "raw = load_dataset(DATASET_NAME)\n",
    "raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c19a74",
   "metadata": {},
   "source": [
    "### (Optional) Use a small subset for quick experiments\n",
    "\n",
    "Training on the full dataset is totally fine, but when you're learning, itâ€™s often nicer to iterate quickly.\n",
    "\n",
    "Set `USE_SMALL_SUBSET=True` to train on a small slice (2000 training samples, 200 validation samples, 500 test samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9212ec8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: ['World', 'Sports', 'Business', 'Sci/Tech']\n",
      "num_labels: 4\n",
      "train/val/test: 1800 200 500\n"
     ]
    }
   ],
   "source": [
    "USE_SMALL_SUBSET = True\n",
    "\n",
    "if USE_SMALL_SUBSET:\n",
    "    train_raw = raw['train'].shuffle(seed=42).select(range(2000))\n",
    "    test_raw  = raw['test'].shuffle(seed=42).select(range(500))\n",
    "else:\n",
    "    train_raw = raw['train']\n",
    "    test_raw  = raw['test']\n",
    "\n",
    "# Create a validation split from the training data\n",
    "split = train_raw.train_test_split(test_size=0.1, seed=42)\n",
    "train_ds = split['train']\n",
    "val_ds   = split['test']\n",
    "\n",
    "label_names = raw['train'].features['label'].names\n",
    "num_labels = len(label_names)\n",
    "print('Labels:', label_names)\n",
    "print('num_labels:', num_labels)\n",
    "print('train/val/test:', len(train_ds), len(val_ds), len(test_raw))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb41a01a",
   "metadata": {},
   "source": [
    "## 3) Tokenization (turn text into model inputs)\n",
    "\n",
    "BERT does not read raw strings. It reads numbers:\n",
    "- **input_ids**: token IDs (words/subwords mapped to integers)\n",
    "- **attention_mask**: 1 for real tokens, 0 for padding\n",
    "\n",
    "We use the model's matching tokenizer so token IDs line up correctly.\n",
    "\n",
    "We'll use **dynamic padding** (pad to the longest sequence in a batch) which is usually faster than padding everything to a fixed length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af854ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1800/1800 [00:00<00:00, 7250.57 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:00<00:00, 6547.72 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:00<00:00, 7222.00 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'label': 0,\n",
       " 'input_ids': [101,\n",
       "  3956,\n",
       "  17910,\n",
       "  2015,\n",
       "  5920,\n",
       "  8647,\n",
       "  2886,\n",
       "  1024,\n",
       "  2557,\n",
       "  5611,\n",
       "  3548,\n",
       "  2031,\n",
       "  17910,\n",
       "  2098,\n",
       "  1037,\n",
       "  2825,\n",
       "  5920,\n",
       "  8647,\n",
       "  2886,\n",
       "  1998,\n",
       "  14620,\n",
       "  1037,\n",
       "  9302,\n",
       "  2450,\n",
       "  1010,\n",
       "  3956,\n",
       "  2557,\n",
       "  2988,\n",
       "  2006,\n",
       "  9432,\n",
       "  1012,\n",
       "  102],\n",
       " 'token_type_ids': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def tokenize_function(batch):\n",
    "    return tokenizer(batch['text'], truncation=True)\n",
    "\n",
    "tokenized_train = train_ds.map(tokenize_function, batched=True, remove_columns=['text'])\n",
    "tokenized_val   = val_ds.map(tokenize_function, batched=True, remove_columns=['text'])\n",
    "tokenized_test  = test_raw.map(tokenize_function, batched=True, remove_columns=['text'])\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# Peek at a tokenized example\n",
    "tokenized_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a75a4a",
   "metadata": {},
   "source": [
    "## 4) Load the model\n",
    "\n",
    "We load a pretrained model **with a classification head**.\n",
    "Setting `num_labels` ensures the output layer matches the number of classes in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b802b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=num_labels,\n",
    "    id2label={i: name for i, name in enumerate(label_names)},\n",
    "    label2id={name: i for i, name in enumerate(label_names)},\n",
    ")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47df2501",
   "metadata": {},
   "source": [
    "## 5) Metrics (evaluation)\n",
    "\n",
    "We'll compute **accuracy** during evaluation.\n",
    "\n",
    "Later, you can add F1/precision/recall (especially useful for imbalanced datasets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8e3243a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 4.20kB [00:00, 3.60MB/s]\n"
     ]
    }
   ],
   "source": [
    "accuracy = evaluate.load('accuracy')\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return accuracy.compute(predictions=preds, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef115c38",
   "metadata": {},
   "source": [
    "## 6) Training\n",
    "\n",
    "Key hyperparameters:\n",
    "- **learning_rate**: how big each update step is (2e-5 is a common BERT starting point)\n",
    "- **batch size**: how many examples per step\n",
    "- **epochs**: passes through the dataset\n",
    "\n",
    "Notes:\n",
    "- If you hit out-of-memory on GPU, reduce `per_device_train_batch_size`.\n",
    "- `fp16=True` can speed things up on many GPUs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4616b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2812057/1656122121.py:23: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/home/pranay/environments/starter_kit/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='87' max='87' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [87/87 00:33, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.129900</td>\n",
       "      <td>0.656158</td>\n",
       "      <td>0.905000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.613700</td>\n",
       "      <td>0.359945</td>\n",
       "      <td>0.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.411400</td>\n",
       "      <td>0.302699</td>\n",
       "      <td>0.940000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pranay/environments/starter_kit/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/pranay/environments/starter_kit/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=87, training_loss=0.6663558291292738, metrics={'train_runtime': 36.2426, 'train_samples_per_second': 148.996, 'train_steps_per_second': 2.4, 'total_flos': 360094500981696.0, 'train_loss': 0.6663558291292738, 'epoch': 3.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "OUTPUT_DIR = '../models/bert-finetuned-ag-news'\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='accuracy',\n",
    "\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "\n",
    "    logging_dir=os.path.join(OUTPUT_DIR, 'logs'),\n",
    "    logging_steps=25,\n",
    "\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    report_to='none',  # change to 'wandb' if you use Weights & Biases to keep track of experiments (highly recommended)\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_val,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39b5c7d",
   "metadata": {},
   "source": [
    "## 7) Evaluate on the test set\n",
    "\n",
    "We trained on `train_ds`, tuned on `val_ds`, and now we report performance on `test_raw`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04456862",
   "metadata": {},
   "source": [
    "Load saved model for inference or further evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06deb82d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pranay/environments/starter_kit/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.4201270639896393,\n",
       " 'eval_accuracy': 0.88,\n",
       " 'eval_runtime': 1.0926,\n",
       " 'eval_samples_per_second': 457.612,\n",
       " 'eval_steps_per_second': 7.322,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_metrics = trainer.evaluate(tokenized_test)\n",
    "test_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59f45c3",
   "metadata": {},
   "source": [
    "## 8) Save the model + tokenizer\n",
    "\n",
    "Saving lets you:\n",
    "- reuse the model later\n",
    "- share it with labmates\n",
    "- upload it to the Hugging Face Hub (optional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75a8a341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: ../models/bert-finetuned-ag-news\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(OUTPUT_DIR)\n",
    "tokenizer.save_pretrained(OUTPUT_DIR)\n",
    "print('Saved to:', OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b644927",
   "metadata": {},
   "source": [
    "## 9) Inference (predict on new text)\n",
    "\n",
    "We'll reload from `OUTPUT_DIR` and run predictions on new sentences.\n",
    "\n",
    "Two beginner-friendly options:\n",
    "1. Use the model directly (`model(**inputs)`) (allows for tweaking)\n",
    "2. Use a `pipeline` (simpler interface shown below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08df10f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'Business', 'score': 0.8443780541419983},\n",
       " {'label': 'Sports', 'score': 0.8677119016647339},\n",
       " {'label': 'Sci/Tech', 'score': 0.789272665977478},\n",
       " {'label': 'World', 'score': 0.8701167702674866}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "clf = pipeline('text-classification', model=OUTPUT_DIR, tokenizer=OUTPUT_DIR, device=0 if torch.cuda.is_available() else -1)\n",
    "\n",
    "sample_texts = [\n",
    "    'The stock market fell sharply after the central bank announcement.',\n",
    "    'The team won the championship after a thrilling final match.',\n",
    "    'Scientists discovered a new method to improve battery life.',\n",
    "    'Diplomats met to discuss a new ceasefire agreement.'\n",
    "]\n",
    "\n",
    "preds = clf(sample_texts)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6678301",
   "metadata": {},
   "source": [
    "## 10) Recommended Next Steps\n",
    "\n",
    "- **Try your own dataset** by loading it and adapting the preprocessing steps \n",
    "- Add **F1/precision/recall** and a confusion matrix\n",
    "- Track experiments with W&B and keep an experiment card (hypothesis -> config -> results)\n",
    "- Look into more advanced models if you are not happy with the performance for your task (decoder-models, larger models, etc.)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Starter Kit",
   "language": "python",
   "name": "starter_kit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
